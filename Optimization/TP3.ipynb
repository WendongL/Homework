{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miguel Colom  \n",
    "Rafael Grompone von Gioi  \n",
    "Argyris Kalogeratos\n",
    "\n",
    "TP3 : Optimisation Numérique  \n",
    "Première Année Master Hadamard\n",
    "\n",
    "# <center>Minimisation par optimisation proximale</center>\n",
    "\n",
    "##  À savoir avant de commencer :\n",
    "  * Vous pouvez préparer votre livrable en français ou en anglais.  \n",
    "  \n",
    "  * Justifiez de manière appropriée les solutions proposées dans le notebook en tant que réponses. Évitez d'ajouter un code qui n'est pas expliqué. Le notebook livré est la combinaison de code et de réponses bien élaborées.\n",
    "\n",
    "  *  Prenez-garde à ce que votre code compile correctement et ne dépende pas d'autres modules que ceux indiqués dans le TP.\n",
    "\n",
    "  *  Lorsque vous comparez plusieurs graphiques, veuillez utiliser la même figure. Ne créez pas de nouvelle figure pour chaque graphique.\n",
    "  \n",
    "  * Ajoutez chaque réponse juste en dessous de chaque question. Là, vous pouvez creer plusieur \"cells\" de code, de résultats/figures, ou de comentaires.\n",
    "\n",
    "  *  $\\rightarrow$ **Seuls les devoirs rendus sur eCampus sont acceptés!** Ils ne doivent jamais être envoyés par mail aux responsables des TP.\n",
    "Veuillez vous assurer que votre accès à eCampus fonctionne correctement. Si ce n'est pas le cas, veuillez contacter immédiatement les responsables pédagogiques ou informatiques.\n",
    "\n",
    "Remarque : la plupart du temps on n'implémente pas les méthodes classiques présentées dans ce TP et on utilise des paquets du type ``scipy``. Néanmoins, il convient de savoir ce que contienne ces _boîtes noires_ et de se forger une intuition sur les différentes méthodes d'optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installer localement les paquets nécessaires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --user scikit-learn\n",
    "!{sys.executable} -m pip install --user scikit-image\n",
    "!{sys.executable} -m pip install --user numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1. Implémentation de ISTA\n",
    "\n",
    "L'algorithme ISTA [1] a pour objectif de minimiser une fonction $F : \\mathbb{R}^d \\to \\mathbb{R}$ s'écrivant sous la forme $F = f + \\lambda g$ où $\\lambda >0$ est une constante,\n",
    "\n",
    "1. $f$ est un fonction convexe, $C^1$, gradient Lipschitz i. e. pour tout $x,y \\in \\mathbb{R}^d$,\n",
    "\n",
    "$$||\\nabla f(x) - \\nabla f(y)|| \\leq L ||x-y||.$$\n",
    "\n",
    "2. $g$ est une fonction continue convexe dont on peut calculer l'opérateur proximal $\\text{prox}_g^{\\gamma}$ défini pour tout $\\gamma >0$ et $x \\in \\mathbb{R}^d$ par\n",
    "\n",
    "$$\\text{prox}_g^{\\gamma}  = \\text{argmin}_{y \\in \\mathbb{R}} \\{g(y) + (2 \\gamma)^{-1} ||x-y||^2 \\}.$$\n",
    "\n",
    "L'algorithme ISTA consiste alors à construire la suite $(x_k)_{k \\in \\mathbb{N}}$ partant de $x_0 \\in \\mathbb{R}^d$ à partir de la récursion suivante :\n",
    "\n",
    "$$x_{k+1} = \\text{prox}_{\\lambda g}^{\\gamma} \\{x_k - \\gamma \\nabla f(x_k)\\}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Montrer que pour tout $\\gamma, \\lambda >0$, on a $$\\text{prox}_{\\lambda g}^{\\gamma} = \\text{prox}_{ g}^{\\lambda \\gamma}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Recherche du minimum global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémenter alors l'algorithme ISTA. On pourra par exemple considérer un fonction sous la forme \n",
    "\n",
    "    ista(x0, prox_op_g, grad_f, fun_total, lambda_l, n_it=100):\n",
    "        Variables d'entree :\n",
    "            * x0 : solution initial\n",
    "            * prox_op_g : operateur proximal de g qui prend en entree x et gamma\n",
    "            * grad_f : fonction qui a partir d'un point x retourne le gradient de f et la constante de Lipschitz du gradient de f\n",
    "            * fun_total : fonction F = f+lambda*g\n",
    "            * lambda_l : parametre lambda dans F\n",
    "            * n_it : nombre d'iterations\n",
    "\n",
    "        Variables de sortie : x, fun_iterate\n",
    "            * x : itere final de ISTA\n",
    "            * fun_iterate : suite (F(x_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rightarrow$ **Plus précisément, nous nous référons à l'Algorithme 4 du Chapitre 7 du polycopié (pas fixe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. Acquisition comprimée (_compressed sensing_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans de nombreux problèmes, notamment en traitement du signal, seulement des observations partielles, regroupées dans un vecteur $y \\in \\mathbb{R}^p$, d'un signal $x \\in \\mathbb{R}^d$ sont disponibles. Cela s'explique par une volonté de compresser le signal par exemple ou encore parce que les instruments de mesures du signal sont dans certains cas peu précis. Mathématiquement, cette perte de données se modélise par une relation $y=Ax$, où $A \\in \\mathbb{R}^{p,d}$, et $p << d$. Comme $A$ n'est pas inversible, le plus souvent le problème inverse $y=Ax$ a de nombreuses solutions mais qui ne sont pas satisfaisantes. En effet, dans de nombreux cas, le signal d'origine $x$ est le plus souvent parcimonieux, i. e. un grand nombre de ses composantes sont nulles. Ainsi, pour reconstruire ce type de signal, il a été proposé de considérer le minimum de la fonction\n",
    "\n",
    "$$F(x) = f(x) + \\lambda g(x), \\qquad f(x) = ||y-Ax||^2, \\qquad g(x) =  \\sum_{i=1}^d |x_i|,$$\n",
    "\n",
    "où $\\lambda >0$ est un coefficient qui contrôle le niveau de parcimonie de $x$.  On peut observer que $F$ peut s'écrire comme $f+g$ où $f$ est une fonction convexe gradient Lipschitz et $g$ est une fonction convexe continue mais non différentiable. On se propose dans cette partie d'appliquer l'algorithme ISTA à la minimisation de $F$\n",
    "avec une application au traitement d'image. Ici $y$ sera une mesure d'une image et $x$ les coefficients en ondelettes de la même image. Ainsi la matrice $A$ est simplement l'opérateur linéaire qui à une représentation en ondelettes associe un signal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Définir les fonctions suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wavelet_filter(type, par):\n",
    "    \"\"\"\n",
    "        compute_wavelet_filter - Generate Orthonormal QMF Filter for Wavelet Transform\n",
    "\n",
    "\n",
    "           [h,g] = compute_wavelet_filter(Type,Par)\n",
    "\n",
    "         Inputs\n",
    "           Type   string, 'Haar', 'Beylkin', 'Coiflet', 'Daubechies',\n",
    "                  'Symmlet', 'Vaidyanathan','Battle'\n",
    "           Par    integer, it is a parameter related to the support and vanishing\n",
    "                  moments of the wavelets, explained below for each wavelet.\n",
    "\n",
    "        Outputs\n",
    "          h   low pass quadrature mirror filter\n",
    "          g   high pass\n",
    "\n",
    "         Description\n",
    "           The Haar filter (which could be considered a Daubechies-2) was the\n",
    "           first wavelet, though not called as such, and is discontinuous.\n",
    "\n",
    "           The Beylkin filter places roots for the frequency response function\n",
    "           close to the Nyquist frequency on the real axis.\n",
    "\n",
    "           The Coiflet filters are designed to give both the mother and father\n",
    "           wavelets 2*Par vanishing moments; here Par may be one of 1,2,3,4 or 5.\n",
    "\n",
    "           The Daubechies filters are minimal phase filters that generate wavelets\n",
    "           which have a minimal support for a given number of vanishing moments.\n",
    "           They are indexed by their length, Par, which may be one of\n",
    "           2,4,6,8,10,12,14,16,18 or 20. The number of vanishing moments is par/2.\n",
    "\n",
    "           Symmlets are also wavelets within a minimum size support for a given\n",
    "           number of vanishing moments, but they are as symmetrical as possible,\n",
    "           as opposed to the Daubechies filters which are highly asymmetrical.\n",
    "           They are indexed by Par, which specifies the number of vanishing\n",
    "           moments and is equal to half the size of the support. It ranges\n",
    "           from 4 to 10.\n",
    "\n",
    "           The Vaidyanathan filter gives an exact reconstruction, but does not\n",
    "           satisfy any moment condition.  The filter has been optimized for\n",
    "           speech coding.\n",
    "\n",
    "           The Battle-Lemarie filter generate spline orthogonal wavelet basis.\n",
    "           The parameter Par gives the degree of the spline. The number of\n",
    "           vanishing moments is Par+1.\n",
    "\n",
    "        See Also\n",
    "           FWT_PO, IWT_PO, FWT2_PO, IWT2_PO, WPAnalysis\n",
    "\n",
    "        References\n",
    "            The books by Daubechies and Wickerhauser.\n",
    "\n",
    "        Warning : only Daubechies implemented for the moment !\n",
    "    \"\"\"\n",
    "\n",
    "    if type == 'Daubechies':\n",
    "\n",
    "        if par == 1:\n",
    "            f = [1, 1] / np.sqrt(2)\n",
    "\n",
    "        elif par == 4:\n",
    "            f = [.482962913145, .836516303738,\n",
    "                 .224143868042, -.129409522551]\n",
    "\n",
    "        elif par == 6:\n",
    "            f = [.332670552950, .806891509311,\n",
    "                 .459877502118, -.135011020010,\n",
    "                 -.085441273882, .035226291882]\n",
    "\n",
    "        elif par == 8:\n",
    "            f = [.230377813309, .714846570553,\n",
    "                 .630880767930, -.027983769417,\n",
    "                 -.187034811719, .030841381836,\n",
    "                 .032883011667, -.010597401785]\n",
    "\n",
    "        elif par == 10:\n",
    "            f = [.160102397974, .603829269797, .724308528438,\n",
    "                 .138428145901, -.242294887066, -.032244869585,\n",
    "                 .077571493840, -.006241490213, -.012580751999,\n",
    "                 .003335725285]\n",
    "\n",
    "        elif par == 12:\n",
    "            f = [.111540743350, .494623890398, .751133908021,\n",
    "                 .315250351709, -.226264693965, -.129766867567,\n",
    "                 .097501605587, .027522865530, -.031582039317,\n",
    "                 .000553842201, .004777257511, -.001077301085]\n",
    "\n",
    "        elif par == 14:\n",
    "            f = [.077852054085, .396539319482, .729132090846,\n",
    "                 .469782287405, -.143906003929, -.224036184994,\n",
    "                 .071309219267, .080612609151, -.038029936935,\n",
    "                 -.016574541631, .012550998556, .000429577973,\n",
    "                 -.001801640704, .000353713800]\n",
    "\n",
    "        elif par == 16:\n",
    "            f = [.054415842243, .312871590914, .675630736297,\n",
    "                 .585354683654, -.015829105256, -.284015542962,\n",
    "                 .000472484574, .128747426620, -.017369301002,\n",
    "                 -.044088253931, .013981027917, .008746094047,\n",
    "                 -.004870352993, -.000391740373, .000675449406,\n",
    "                 -.000117476784]\n",
    "\n",
    "        elif par == 18:\n",
    "            f = [.038077947364, .243834674613, .604823123690,\n",
    "                 .657288078051, .133197385825, -.293273783279,\n",
    "                 -.096840783223, .148540749338, .030725681479,\n",
    "                 -.067632829061, .000250947115, .022361662124,\n",
    "                 -.004723204758, -.004281503682, .001847646883,\n",
    "                 .000230385764, -.000251963189, .000039347320]\n",
    "\n",
    "        elif par == 20:\n",
    "            f = [.026670057901, .188176800078, .527201188932,\n",
    "                 .688459039454, .281172343661, -.249846424327,\n",
    "                 -.195946274377, .127369340336, .093057364604,\n",
    "                 -.071394147166, -.029457536822, .033212674059,\n",
    "                 .003606553567, -.010733175483, .001395351747,\n",
    "                 .001992405295, -.000685856695, -.000116466855,\n",
    "                 .000093588670, -.000013264203]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unimplemented for par={par}\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Wrong arguments, see comments for acceptable values\")\n",
    "\n",
    "    f = list(f / np.linalg.norm(f))\n",
    "\n",
    "    if len(f) % 2 == 0:\n",
    "        f = [0] + f\n",
    "\n",
    "    return np.array(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "\n",
    "def upsampling(x, d):\n",
    "    \"\"\"\n",
    "    up-sampling along dimension d by factor p=2\n",
    "    \"\"\"\n",
    "    p = 2\n",
    "    s = x.shape\n",
    "    if d == 1:\n",
    "        y = np.zeros((p * s[0], s[1]))\n",
    "        y[::p, :] = x\n",
    "    elif d == 2:\n",
    "        y = np.zeros((s[0], p * s[1]))\n",
    "        y[:, ::p] = x\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    return y\n",
    "\n",
    "\n",
    "def subsampling(x, d):\n",
    "    \"\"\"\n",
    "    subsampling along dimension d by factor p=2\n",
    "    \"\"\"\n",
    "    p = 2\n",
    "    if d == 1:\n",
    "        y = x[::p, :]\n",
    "    elif d == 2:\n",
    "        y = x[:, ::p]\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    return y\n",
    "\n",
    "\n",
    "def rescale(f, a=0, b=1):\n",
    "    \"\"\"\n",
    "    Rescale linearly the dynamic of a vector to fit within a range [a,b]\n",
    "    \"\"\"\n",
    "    v = f.max() - f.min()\n",
    "    g = (f - f.min()).copy()\n",
    "    if v > 0:\n",
    "        g = g * 1 / v\n",
    "    return a * 1 + g * (b - a)\n",
    "\n",
    "\n",
    "def load_image(name, n=-1, flatten=1, resc=1, grayscale=1):\n",
    "    \"\"\"\n",
    "    Load an image from a file, rescale its dynamic to [0,1], turn it into a grayscale image\n",
    "    and resize it to size n x n.\n",
    "    \"\"\"\n",
    "    f = plt.imread(name)\n",
    "    # turn into normalized grayscale image\n",
    "    if grayscale == 1:\n",
    "        if flatten == 1 and np.ndim(f) > 2:\n",
    "            f = np.sum(f, axis=2)\n",
    "    if resc == 1:\n",
    "        f = rescale(f)\n",
    "    # change the size of the image\n",
    "    if n > 0:\n",
    "        if np.ndim(f) == 2:\n",
    "            f = transform.resize(f, [n, n], 1)\n",
    "        elif np.ndim(f) == 3:\n",
    "            f = transform.resize(f, [n, n, f.shape[2]], 1)\n",
    "    return f\n",
    "\n",
    "\n",
    "def circshift1d(x, k):\n",
    "    \"\"\" \n",
    "    Circular shift of a 1D vector\n",
    "    \"\"\"\n",
    "    return np.roll(x, -k, axis=0)\n",
    "\n",
    "\n",
    "def cconv(x, h, d):\n",
    "    \"\"\"\n",
    "    Circular convolution along dimension d.\n",
    "    h should be small and with odd size\n",
    "    \"\"\"\n",
    "    if d == 2:\n",
    "        # apply to transposed matrix\n",
    "        return np.transpose(cconv(np.transpose(x), h, 1))\n",
    "    y = np.zeros(x.shape)\n",
    "    p = len(h)\n",
    "    pc = int(round(float((p - 1) / 2)))\n",
    "    for i in range(0, p):\n",
    "        y = y + h[i] * circshift1d(x, i - pc)\n",
    "    return y\n",
    "\n",
    "\n",
    "def reverse(x):\n",
    "    \"\"\"\n",
    "    Reverse a vector. \n",
    "    \"\"\"\n",
    "    return x[::-1]\n",
    "\n",
    "\n",
    "def perform_wavortho_transf(f, Jmin, dir, h):\n",
    "    \"\"\"\n",
    "    perform_wavortho_transf - compute orthogonal wavelet transform\n",
    "\n",
    "    fw = perform_wavortho_transf(f,Jmin,dir,options);\n",
    "\n",
    "    You can give the filter in options.h.\n",
    "\n",
    "    Works in 2D only.\n",
    "    Copyright (c) 2014 Gabriel Peyre\n",
    "    \"\"\"\n",
    "\n",
    "    n = f.shape[1]\n",
    "    Jmax = int(np.log2(n) - 1)\n",
    "    # compute g filter\n",
    "    u = np.power(-np.ones(len(h) - 1), range(1, len(h)))\n",
    "    # alternate +1/-1\n",
    "    g = np.concatenate(([0], h[-1:0:-1] * u))\n",
    "\n",
    "    if dir == 1:\n",
    "        ### FORWARD ###\n",
    "        fW = f.copy()\n",
    "        for j in np.arange(Jmax, Jmin - 1, -1):\n",
    "            A = fW[:2 ** (j + 1):, :2 ** (j + 1):]\n",
    "            for d in np.arange(1, 3):\n",
    "                Coarse = subsampling(cconv(A, h, d), d)\n",
    "                Detail = subsampling(cconv(A, g, d), d)\n",
    "                A = np.concatenate((Coarse, Detail), axis=d - 1)\n",
    "            fW[:2 ** (j + 1):, :2 ** (j + 1):] = A\n",
    "        return fW\n",
    "    else:\n",
    "        ### BACKWARD ###\n",
    "        fW = f.copy()\n",
    "        f1 = fW.copy()\n",
    "        for j in np.arange(Jmin, Jmax + 1):\n",
    "            A = f1[:2 ** (j + 1):, :2 ** (j + 1):]\n",
    "            for d in np.arange(1, 3):\n",
    "                if d == 1:\n",
    "                    Coarse = A[:2**j:, :]\n",
    "                    Detail = A[2**j: 2**(j + 1):, :]\n",
    "                else:\n",
    "                    Coarse = A[:, :2 ** j:]\n",
    "                    Detail = A[:, 2 ** j:2 ** (j + 1):]\n",
    "                Coarse = cconv(upsampling(Coarse, d), reverse(h), d)\n",
    "                Detail = cconv(upsampling(Detail, d), reverse(g), d)\n",
    "                A = Coarse + Detail\n",
    "            f1[:2 ** (j + 1):, :2 ** (j + 1):] = A\n",
    "        return f1\n",
    "\n",
    "\n",
    "def noisy_observations(n=32, r_sparse=0.2, r_info=0.5):\n",
    "    \"\"\"\n",
    "    Measurement function.\n",
    "\n",
    "    Parameters:\n",
    "    - n is the image size (n x n);\n",
    "    - r_sparse is the ratio of non-zero coefficients (wavelet domain) of the\n",
    "    signal x to recover;\n",
    "    - r_info is the ratio between the size of y and the size of x.\n",
    "\n",
    "    Return y, A,  where:\n",
    "    - y is the vector of measurements;\n",
    "    - A is the sensing matrix (we look for x such that y = Ax);\n",
    "    \"\"\"\n",
    "\n",
    "    # Load Barbara's test imageimport urllib.requestimport urllib.request\n",
    "    im = rescale(load_image(\"https://mcolom.perso.math.cnrs.fr/data/tps/optimisation/barb.png\", n))\n",
    "\n",
    "    h = compute_wavelet_filter(\"Daubechies\", 4)\n",
    "\n",
    "    # Compute the matrix of wavelet transform\n",
    "    mask = np.zeros((n, n))\n",
    "    A0 = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mask[i, j] = 1\n",
    "            wt = perform_wavortho_transf(mask, 0, +1, h)\n",
    "            A0.append(wt.ravel())\n",
    "            mask[i, j] = 0\n",
    "    A0 = np.asarray(A0)\n",
    "\n",
    "    # Gaussian matrix x Wavelet transform (keep ratio r_info)\n",
    "    G = np.random.randn(int(np.floor(n**2 * r_info)), n**2) / n\n",
    "    A = G.dot(A0)\n",
    "\n",
    "    # Threshold the image (keep ratio r_sparse) and generate the measurements y\n",
    "    # Same as x_true = A0.T.dot(im.flatten())\n",
    "    x_true = perform_wavortho_transf(im, 0, +1, h).ravel()\n",
    "    thshol = np.sort(np.abs(x_true.ravel()))[int((1 - r_sparse) * n**2)]\n",
    "    x_true[np.abs(x_true) <= thshol] = 0\n",
    "    y = A.dot(x_true)  # Vector of measurements\n",
    "    return y, A\n",
    "\n",
    "\n",
    "def back_to_image(x):\n",
    "    n = int(np.sqrt(x.size))\n",
    "    h = compute_wavelet_filter(\"Daubechies\", 4)\n",
    "    wt = x.reshape((n, n))\n",
    "    im = perform_wavortho_transf(wt, 0, -1, h)\n",
    "    return im\n",
    "\n",
    "\n",
    "def plot_image(x):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    im = back_to_image(x)\n",
    "    plt.imshow(im, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "def total_variation_op(n=32):\n",
    "    \"\"\"\n",
    "    Measurement function.\n",
    "\n",
    "    Parameters:\n",
    "    - n is the image size (n x n);\n",
    "\n",
    "    Return T a total variation operator.\n",
    "    \"\"\"\n",
    "    h = compute_wavelet_filter(\"Daubechies\", 4)\n",
    "\n",
    "    # Compute the matrix of wavelet transform\n",
    "    mask = np.zeros((n, n))\n",
    "    A0 = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mask[i, j] = 1\n",
    "            wt = perform_wavortho_transf(mask, 0, +1, h)\n",
    "            A0.append(wt.ravel())\n",
    "            mask[i, j] = 0\n",
    "    A0 = np.asarray(A0)\n",
    "\n",
    "    # Total variation operator\n",
    "    dx = np.eye(n**2)\n",
    "    dx -= np.roll(dx, 1, axis=1)\n",
    "    dx = np.delete(dx, np.s_[n - 1::n], axis=0)\n",
    "\n",
    "    dy = np.eye(n**2)\n",
    "    dy -= np.roll(dy, n, axis=1)\n",
    "    dy = np.delete(dy, np.s_[-n:], axis=0)\n",
    "\n",
    "    T = np.r_[dx, dy].dot(A0)  # TV in the image domain\n",
    "\n",
    "    T = np.r_[np.eye(n**2), T]  # For usual L1 norm, add identity\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "def noisy_observation_inf(n=2**4):\n",
    "    A = np.zeros((n, n))\n",
    "    while np.linalg.det(A) == 0:\n",
    "        A = np.random.randn(n, n)\n",
    "    y = A.dot(np.ones(n)) + np.random.randn(n)\n",
    "    return y, A\n",
    "\n",
    "\n",
    "def noisy_observation_nuclear(n=2**4):\n",
    "    A = np.random.binomial(1, 0.1, size=(n, n))\n",
    "    while np.sum(A) <= n / 5:\n",
    "        A = np.random.binomial(1, 0.1, size=(n, n))\n",
    "    X = np.ones((n, n))\n",
    "    Y = A * X\n",
    "    return Y, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Générer les données $A$ et $y$ et fixer pour le moment $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_l1 = 1\n",
    "y, A = noisy_observations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Calculer le gradient de $f$ pour cet exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Dans cette question, on s'intéresse au calcul de l'opérateur proximal de $g$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) Soit $h$ une fonction convexe sci propre sur $\\mathbb{R}^d$ sous la forme $h(x)= \\sum_{i=1}^d h_i(x_i)$, pour tout $x = (x_i,\\ldots,x_d)\\in \\mathbb{R}^d$, où pour tout $i \\in \\{1,\\ldots,d\\}$, $h_i : \\mathbb{R} \\to (-\\infty, +\\infty]$, est convexe sci propre. Montrer que pour tout $x \\in \\mathbb{R}^d$ et $\\gamma >0$, $$\\text{prox}_h^{\\gamma}(x) = (\\text{prox}_{h_i}^{\\gamma}(x_i))_{i \\in \\{1, \\ldots, d\\}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) Considérons $\\phi(t) = |t|$ pour tout $t \\in \\mathbb{R}$. Montrer que pour tout $u \\in \\mathbb{R}$ et $\\gamma >0$ $$t^{\\star} = \\text{argmin}_{t \\in \\mathbb{R}} \\{|t| + (2\\gamma)^{-1} |t-u|^2\\},$$ si et seulement si $$t^* \\in u - \\gamma \\partial \\phi(t^*).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c) Déterminer la sous-différentielle de $\\phi$ sur $\\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d) En distinguant les cas $|u| < \\gamma$ et $|u| \\geq \\gamma$, déterminer pour tout $u \\in \\mathbb{R}$ et $\\gamma >0$, $\\text{prox}_{\\phi}^{\\gamma}(u)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4e) En déduire $\\text{prox}_{g}^{\\gamma}(x)$ pour tout $x \\in \\mathbb{R}^d$ et $\\gamma >0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Implémenter le gradient de $f$ et l'opérateur proximal de $g$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Appliquer la fonction ista que vous avez précédemment codé pour minimiser $F$ et afficher l'image que vous obtenez à l'aide la fonction `plot_image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Vérifier numériquement que l'ordre de convergence de ISTA est de l'ordre $O(k^{-1})$ où $k$ est le nombre d'itérations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Changer la valeur du paramètre $\\lambda$ et afficher les images que vous obtenez. Discuter de vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3. Complétion de matrice de faible rang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, on s'intéresse au problème de complétion de\n",
    "matrice. Dans certains problèmes statistiques, on a accès à seulement\n",
    "certaines entrées d'une matrice $X \\in \\mathbb{R}^{d \\times d}$,\n",
    "$Y = A \\odot X$ où\n",
    "$A =(\\mathbf{1}_{I \\times J}((i,j)))_{i,j \\in \\{1,\\ldots,d\\}}$, où\n",
    "$I,J \\subset \\{1,\\ldots,d\\}$ et $\\odot$ est la multiplication élément\n",
    "par élément (ou appelé par certains \"matlab\").  Dans ce problème, on\n",
    "voudrait alors retrouver les composantes manquantes de $X$. Pour cela,\n",
    "il est commun de chercher une matrice $X$ de faible rang. Cela revient\n",
    "alors à chercher à minimiser la fonction $F$ définie sur $\\mathbb{R}^{d\\times d}$ par\n",
    "\\begin{equation*}\n",
    "  F(X) = f(X) + \\lambda g(X), \\qquad f(X) = ||Y-A\\odot X||^2_{2}, \\, g(X )= ||X||_{\\star}  = \\sum_{i=1}^d |\\sigma_i(X)|,\n",
    "\\end{equation*}\n",
    "où $||\\cdot||_2$ est la norme de Frobenius et\n",
    "$(\\sigma_i)_{i \\in \\{1,\\ldots,d\\}}$ sont les valeurs singulières de\n",
    "$X$. On rappelle le théorème de décomposition en valeurs propres\n",
    "singulières:\n",
    "\n",
    "__Théorème 1__\n",
    "_Soit $A \\in \\mathbb{R}^{d \\times m}$, $d \\leq m$. Il existe alors deux matrices orthogonales $O_1,O_2$ et $\\sigma_1(A) \\geq \\cdots \\geq \\sigma_d(A) \\geq 0$ tel que $A = O_1 \\Sigma O_2$ où $\\Sigma_A \\in \\mathbb{R}^{d \\times m}$ est la matrice dont les entrées sont données par $\\Sigma_{i,i} = \\sigma_i(A)$ pour $i \\in\\{1,\\ldots,d\\}$ et $\\Sigma_{i,j} = 0$ sinon.  Les réels $(\\sigma_1(A), \\ldots, \\sigma_d(A))$ sont appelés les valeurs singulières de $A$ et sont les valeurs propres de $A A^T$._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Montrer que $g$ est la norme dual de la norme opérateur $|||\\cdot|||$ sur $\\mathbb{R}^{d \\times d}$, i. e.\n",
    "  \\begin{equation*}\n",
    "    g(X) = \\sup_{V \\in \\mathbb{R}^{d \\times d}, \\, |||V||| \\leq 1} \\langle X,V\\rangle = \\sup_{V \\in \\mathbb{R}^{d \\times d}, \\, |||V||| \\leq 1}\\text{Tr}(X^TV),\n",
    "  \\end{equation*}\n",
    " où $|||V|||$ est la norme spectral de $V$ (son valeur singulière le plus grand).\n",
    "\n",
    " En déduire que $g$ est convexe.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On cherche alors à appliquer ISTA pour minimiser $F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Générer les données $A$ et $y$ et fixer pour le moment $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_nuclear = 1\n",
    "Y, A = noisy_observation_nuclear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Calculer le gradient de $f$ pour cet exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Dans cette question, on s'intéresse au calcul de l'opérateur proximal de $g$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) En utilisant que la norme de Frobenius est invariant par rotation, montrer que pour tout $X \\in \\mathbb{R}^{d \\times d}$  le problème de minimisation\n",
    "$$\n",
    "  \\min_{Y \\in \\mathbb{R}^{d\\times d} } ||Y||_{\\star} +(2\\gamma)^{-1} ||Y-X||^2_2, \\qquad\\qquad\\qquad (1)\n",
    "$$\n",
    "est équivalent à\n",
    "$$\n",
    "    \\min_{D \\in \\mathsf{E}} ||D||_{\\star} +(2\\gamma)^{-1} ||D-\\Sigma_X||^2_2, \\qquad\\qquad\\qquad (2)\n",
    "$$\n",
    "où $\\mathsf{E}$ est l'ensemble des matrices diagonales de $\\mathbb{R}^{d \\times d}$ et $\\Sigma_X$ est la matrice diagonale donnée par la décomposition en valeurs singulières de $X$.  Pour cela on utilisera le résultat suivant [2].\n",
    "\n",
    "__Théorème 2__\n",
    "_Soit $A,B \\in \\mathbb{R}^{d \\times d}$ deux matrices de dimension $d$. Alors pour toutes matrices orthogonales $O_1,O_2$,\n",
    "$$\n",
    "\\langle O_1 A O_2,B\\rangle \\leq \\langle\\Sigma_A,\\Sigma_B\\rangle,\n",
    "$$\n",
    "où $\\Sigma_A$ et $\\Sigma_B$ sont les deux matrices diagonales données par la décomposition en valeurs singulières de respectivement $A$ et $B$._\n",
    "\n",
    "Si $D$ est une solution de (2), comment construire $Y$ solution de (1) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) En déduire que pour tout $\\gamma >0$ et $X \\in \\mathbb{R}^{d \\times d}$\n",
    "$$\n",
    "      \\text{prox}_g^{\\gamma}(X) = U \\text{prox}_{\\ell_1}^{\\gamma}(\\Sigma_X) V,\n",
    "$$\n",
    "où $X = U \\Sigma_X V$ est une décomposition en valeurs singulières\n",
    "de $X$ et $\\text{prox}_{\\ell_1}^{\\gamma}$ est l'operateur proximal de la\n",
    "norme $\\ell_1$, $Y \\mapsto \\sum_{i,j=1}^d |Y_{i,j}|$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Implémenter l'opérateur proximal de $g$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Tester l'algorithme ISTA et illustrer graphiquement sa convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Références"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for\n",
    "linear inverse problems. SIAM journal on imaging sciences, 2(1) :183–202, 2009.\n",
    "\n",
    "[2] J. von Neumann, Some matrix-inequalities and metrization of matric-space,\n",
    "Tomsk Univ. Rev, 1(11) :286--300, 1937.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
